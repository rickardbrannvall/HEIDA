{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch\n",
    "#!pip install torchmetrics\n",
    "#!pip install torchvision \n",
    "#!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedMNIST v2.1.0 @ https://github.com/MedMNIST/MedMNIST/\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import tenseal as ts\n",
    "from time import time\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We first work on a 2D dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheme: tfhe, n_parts: 2, poly_choice: 0\n",
      "n_channels: 3, n_classes: 7\n"
     ]
    }
   ],
   "source": [
    "#data_flag = 'pathmnist'\n",
    "#data_flag = 'breastmnist'\n",
    "data_flag = 'dermamnist'\n",
    "\n",
    "verbose = False\n",
    "#scheme = [\"plain\", \"tfhe\", \"ckks\"][1]\n",
    "#n_parts = 2\n",
    "#poly_choice = 0\n",
    "#N_rounds = 10\n",
    "\n",
    "print(f\"scheme: {scheme}, n_parts: {n_parts}, poly_choice: {poly_choice}\")\n",
    "\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "print(f\"n_channels: {n_channels}, n_classes: {n_classes}\")\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, we read the MedMNIST data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/jovyan/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/jovyan/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /home/jovyan/.medmnist/dermamnist.npz\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "\n",
    "pil_dataset = DataClass(split='train', download=download)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7007 7007 3504 7008\n"
     ]
    }
   ],
   "source": [
    "n_subset = int(len(train_dataset)/n_parts)+1\n",
    "\n",
    "idxs = list(range(len(train_dataset)))\n",
    "random.shuffle(idxs)\n",
    "\n",
    "print(len(train_dataset), len(idxs), n_subset, n_subset*n_parts)\n",
    "\n",
    "subsets = [Subset(train_dataset, idxs[i*n_subset:(i+1)*n_subset]) for i in range(n_parts)] \n",
    "loaders = [data.DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True) for dataset in subsets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    print(train_dataset)\n",
    "    print(\"===================\")\n",
    "    print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# montage\n",
    "\n",
    "if verbose:\n",
    "    train_dataset.montage(length=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then, we define a simple model for illustration, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, mobilenet_v3_small, mnasnet1_3\n",
    "from torch import nn\n",
    "\n",
    "def init():\n",
    "    #model = resnet18(num_classes=n_classes) # MNIST has 10 classes\n",
    "    model = resnet18(num_classes=n_classes) # MNIST has 10 classes\n",
    "    for i, param in enumerate(model.parameters()):\n",
    "        pass\n",
    "\n",
    "    model_length = i\n",
    "    for i, param in enumerate(model.parameters()):\n",
    "        if i < model_length - 1:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    if task == \"multi-label, binary-class\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    return model, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state_dict = model.state_dict()\n",
    "\n",
    "def flatten_trainable(model):\n",
    "    all_trainable = []\n",
    "    state_dict = model.state_dict().copy()\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        no_params = parameter.numel()\n",
    "        #print(name, no_params)\n",
    "        all_trainable += state_dict[name].flatten().tolist()\n",
    "    return all_trainable\n",
    "\n",
    "def reshape_trainable(model, all_trainable):\n",
    "    state_dict = model.state_dict().copy()\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        n = parameter.numel()\n",
    "        #print(name, n)\n",
    "        this_param, all_trainable = all_trainable[:n], all_trainable[n:]\n",
    "        this_shape = state_dict[name].shape\n",
    "        state_dict[name] = torch.tensor(this_param).reshape(this_shape)\n",
    "    return state_dict\n",
    "\n",
    "#trainable_params = flatten_trainable(model)\n",
    "#print(len(trainable_params))\n",
    "\n",
    "#test = reshape_trainable(model, trainable_params)\n",
    "#for name, parameter in model.named_parameters():\n",
    "#    print((test[name] == state_dict[name]).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition_tree_plain(parts):\n",
    "    #print(\"addition_tree_plain\")\n",
    "    n = len(parts)\n",
    "    times = [-1,-1,-1,-1]\n",
    "    if n==1:\n",
    "        return times, parts[0]\n",
    "    else:\n",
    "        return times, addition_tree_plain(parts[:n//2])[1] + addition_tree_plain(parts[n//2:])[1] \n",
    "\n",
    "def addition_tree_tfhe(parts, key):\n",
    "    #print(\"addition_tree_tfhe\")\n",
    "    n_vectors = len(parts)\n",
    "    m_entries = len(parts[0])\n",
    "    v_concat = np.concatenate(parts)\n",
    "    if np.max(v_concat) > upper:\n",
    "        print(f\"warning {np.max(v_concat)}>{upper}\")\n",
    "    if np.min(v_concat) < lower:\n",
    "        print(f\"warning {np.min(v_concat)}<{lower}\")        \n",
    "    all_txt = \" \".join([\"%f\"%a for a in v_concat])\n",
    "    command = f\"target/release/add_vectors {key} {prec} {padd} {lower} {upper} {n_vectors} {m_entries} {all_txt}\"\n",
    "    #print(command)\n",
    "    out = subprocess.getoutput(command).split(\"\\n\")[-1]\n",
    "    #print(out)\n",
    "    times, result = out.split(\" [\")\n",
    "    #print(times)\n",
    "    times = [float(a) for a in times.split(\" \")]\n",
    "    result = [float(a) for a in result[:-1].split(\",\")]\n",
    "    result = np.array(result)\n",
    "    return times, result\n",
    "\n",
    "def addition_tree_ckks(vecs, context):\n",
    "    #print(\"addition_tree_ckks\")\n",
    "    n_vectors = len(vecs)\n",
    "    t0 = time()\n",
    "    vecs_enc = [ts.ckks_vector(context, v) for v in vecs]\n",
    "    enc_time = (time()-t0)/n_vectors\n",
    "    t0 = time()\n",
    "    _, aggr_enc = addition_tree_plain(vecs_enc)\n",
    "    add_time = (time()-t0)\n",
    "    t0 = time()\n",
    "    aggr_vec = aggr_enc.decrypt()\n",
    "    dec_time = (time()-t0)\n",
    "    return (-1, enc_time, add_time, dec_time), aggr_vec\n",
    "\n",
    "testlist = [1,2,3,4]\n",
    "#addition_tree_plain(testlist)\n",
    "#addition_tree_ckks([torch.tensor([a]) for a in testlist], context)\n",
    "#addition_tree_ckks([np.array([a]) for a in testlist], context)\n",
    "#addition_tree_ckks([[a] for a in testlist], context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhe_256\n"
     ]
    }
   ],
   "source": [
    "# cryptographic parameters\n",
    "\n",
    "if scheme==\"tfhe\":\n",
    "    context = [256, 512, 1024][poly_choice]\n",
    "    key = {None:\"N/A\",  256:\"keys/def_80_256_1\", 512:\"keys/def_80_512_1\", 1024:\"keys/def_80_2014_1\"}[context]\n",
    "    prec = 6\n",
    "    padd = int(np.log2(n_parts))\n",
    "    lower = -1.0\n",
    "    upper = 1.0\n",
    "    addition_tree = lambda parts: addition_tree_tfhe(parts, key)\n",
    "    max_vec_length = 500\n",
    "    model_name = f\"tfhe_{context}\"\n",
    "    \n",
    "elif scheme==\"ckks\":\n",
    "    param = [4096,8192][poly_choice]\n",
    "    if param==4096:\n",
    "        poly_mod_degree = 4096\n",
    "        coeff_mod_bit_sizes = [40, 20, 40]\n",
    "        context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "        context.global_scale = 2 ** 20\n",
    "    else:\n",
    "        poly_mod_degree = 8192\n",
    "        #coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 21, 21, 40]\n",
    "        coeff_mod_bit_sizes = [60,40,40,60]\n",
    "        context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes)\n",
    "        #context.global_scale = 2 ** 21\n",
    "        context.global_scale = 2 ** 40\n",
    "    # this key is needed for doing dot-product operations\n",
    "    context.generate_galois_keys()\n",
    "    addition_tree = lambda parts: addition_tree_ckks(parts, context)\n",
    "    max_vec_length = param//2\n",
    "    model_name = f\"ckks_{param}\"\n",
    "\n",
    "else:\n",
    "    addition_tree = addition_tree_plain\n",
    "    max_vec_length = 10000000000000000\n",
    "    model_name = f\"plain_text\"\n",
    "    \n",
    "print(model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_distr(verbose = False):\n",
    "\n",
    "    model, criterion, optimizer = init()\n",
    "    global_state = model.state_dict().copy()\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        if verbose: print(f\"epoch: {epoch+1}\")\n",
    "        params = []\n",
    "\n",
    "        for i in range(n_parts):\n",
    "            if verbose: print(f\"part: {i+1}\")\n",
    "            model.load_state_dict(global_state.copy())\n",
    "            model.train()\n",
    "             \n",
    "            for inputs, targets in loaders[i]:\n",
    "                # forward + backward + optimize\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                if task == 'multi-label, binary-class':\n",
    "                    targets = targets.to(torch.float32)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                else:\n",
    "                    targets = targets.squeeze().long()\n",
    "                    loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            trainable_params = flatten_trainable(model)        \n",
    "            n_chunks = int(np.ceil((len(trainable_params)/max_vec_length)))\n",
    "            params.append(np.array_split(trainable_params, n_chunks))\n",
    "\n",
    "        aggr_params = []\n",
    "        for j in range(n_chunks):\n",
    "            times, aggr_chunk = addition_tree([params[i][j] for i in range(n_parts)])\n",
    "            aggr_params.append(aggr_chunk)\n",
    "        aggr_params = np.concatenate(aggr_params)/n_parts\n",
    "\n",
    "        global_state = reshape_trainable(model, list(aggr_params))\n",
    "        \n",
    "    model.load_state_dict(global_state.copy())\n",
    "    \n",
    "    return [t*n_chunks for t in times], model\n",
    "    \n",
    "if verbose:\n",
    "    times, model = train_distr(verbose = False)\n",
    "    times \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "def test(split, model):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "    \n",
    "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.numpy()\n",
    "        y_score = y_score.detach().numpy()\n",
    "        \n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    return metrics\n",
    "        \n",
    "if verbose:\n",
    "    print('==> Evaluating ...')\n",
    "\n",
    "    metrics = test('train', model)\n",
    "    print('train  auc: %.3f  acc:%.3f' % metrics)\n",
    "\n",
    "    metrics = test('test', model)\n",
    "    print('test  auc: %.3f  acc:%.3f' % metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect stats for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 completed in 277.39720129966736\n",
      "Round 2 completed in 257.21616435050964\n",
      "Round 3 completed in 273.9937992095947\n",
      "Round 4 completed in 268.4945878982544\n",
      "Round 5 completed in 272.4022145271301\n",
      "Round 6 completed in 266.8021488189697\n",
      "Round 7 completed in 271.58902168273926\n",
      "Round 8 completed in 282.976717710495\n",
      "Round 9 completed in 265.8248641490936\n",
      "Round 10 completed in 269.79818201065063\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>param</th>\n",
       "      <th>n_parts</th>\n",
       "      <th>crypt_time</th>\n",
       "      <th>crypt_acc</th>\n",
       "      <th>enc_time</th>\n",
       "      <th>add_time</th>\n",
       "      <th>dec_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>266.208445</td>\n",
       "      <td>0.693766</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>248.608489</td>\n",
       "      <td>0.682294</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>260.884558</td>\n",
       "      <td>0.676808</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>257.798172</td>\n",
       "      <td>0.687781</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>261.999813</td>\n",
       "      <td>0.688279</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>258.201778</td>\n",
       "      <td>0.682294</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>259.196676</td>\n",
       "      <td>0.680798</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>252.307324</td>\n",
       "      <td>0.684289</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>254.130729</td>\n",
       "      <td>0.686284</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>plain</td>\n",
       "      <td>none</td>\n",
       "      <td>8</td>\n",
       "      <td>261.705513</td>\n",
       "      <td>0.689776</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model param  n_parts  crypt_time  crypt_acc  enc_time  add_time  dec_time\n",
       "0  plain  none        8  266.208445   0.693766        -1        -1        -1\n",
       "1  plain  none        8  248.608489   0.682294        -1        -1        -1\n",
       "2  plain  none        8  260.884558   0.676808        -1        -1        -1\n",
       "3  plain  none        8  257.798172   0.687781        -1        -1        -1\n",
       "4  plain  none        8  261.999813   0.688279        -1        -1        -1\n",
       "5  plain  none        8  258.201778   0.682294        -1        -1        -1\n",
       "6  plain  none        8  259.196676   0.680798        -1        -1        -1\n",
       "7  plain  none        8  252.307324   0.684289        -1        -1        -1\n",
       "8  plain  none        8  254.130729   0.686284        -1        -1        -1\n",
       "9  plain  none        8  261.705513   0.689776        -1        -1        -1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst = []\n",
    "\n",
    "for i in range(N_rounds):\n",
    "    row = model_name.split(\"_\")\n",
    "    row.append(n_parts)\n",
    "            \n",
    "    t0 = time()\n",
    "    times, model = train_distr(verbose=False)\n",
    "    row.append(time()-t0)\n",
    "\n",
    "    accuracy = test('test', model)[1]\n",
    "    row.append(accuracy)\n",
    "    \n",
    "    #row.append(times[0])\n",
    "    row.append(times[1])\n",
    "    row.append(times[2])\n",
    "    row.append(times[3])\n",
    "    \n",
    "    tst.append(row)\n",
    "    if N_rounds <= 10 or i%(N_rounds//10)==0 or i == N_rounds-1:\n",
    "        print(f\"Round {i+1} completed in {time()-t0}\")\n",
    "\n",
    "res = pd.DataFrame(tst, columns=[\"model\", \"param\", \"n_parts\", \"crypt_time\",\"crypt_acc\",\"enc_time\",\"add_time\",\"dec_time\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_parts</th>\n",
       "      <th>crypt_time</th>\n",
       "      <th>crypt_acc</th>\n",
       "      <th>enc_time</th>\n",
       "      <th>add_time</th>\n",
       "      <th>dec_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.0</td>\n",
       "      <td>258.104150</td>\n",
       "      <td>0.685237</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.189860</td>\n",
       "      <td>0.004934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.0</td>\n",
       "      <td>248.608489</td>\n",
       "      <td>0.676808</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.0</td>\n",
       "      <td>255.047590</td>\n",
       "      <td>0.682294</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.0</td>\n",
       "      <td>258.699227</td>\n",
       "      <td>0.685287</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.0</td>\n",
       "      <td>261.500274</td>\n",
       "      <td>0.688155</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.0</td>\n",
       "      <td>266.208445</td>\n",
       "      <td>0.693766</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_parts  crypt_time  crypt_acc  enc_time  add_time  dec_time\n",
       "count     10.0   10.000000  10.000000      10.0      10.0      10.0\n",
       "mean       8.0  258.104150   0.685237      -1.0      -1.0      -1.0\n",
       "std        0.0    5.189860   0.004934       0.0       0.0       0.0\n",
       "min        8.0  248.608489   0.676808      -1.0      -1.0      -1.0\n",
       "25%        8.0  255.047590   0.682294      -1.0      -1.0      -1.0\n",
       "50%        8.0  258.699227   0.685287      -1.0      -1.0      -1.0\n",
       "75%        8.0  261.500274   0.688155      -1.0      -1.0      -1.0\n",
       "max        8.0  266.208445   0.693766      -1.0      -1.0      -1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = res.describe()\n",
    "tmp.to_csv(f\"figs/stats_{data_flag}_{model_name}_{n_parts}_{N_rounds}.csv\")\n",
    "tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(f\"figs/results_{data_flag}_{model_name}_{n_parts}_{N_rounds}.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 14, 14]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
      "              ReLU-3           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
      "            Conv2d-5             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
      "              ReLU-7             [-1, 64, 7, 7]               0\n",
      "            Conv2d-8             [-1, 64, 7, 7]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
      "             ReLU-10             [-1, 64, 7, 7]               0\n",
      "       BasicBlock-11             [-1, 64, 7, 7]               0\n",
      "           Conv2d-12             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-13             [-1, 64, 7, 7]             128\n",
      "             ReLU-14             [-1, 64, 7, 7]               0\n",
      "           Conv2d-15             [-1, 64, 7, 7]          36,864\n",
      "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
      "             ReLU-17             [-1, 64, 7, 7]               0\n",
      "       BasicBlock-18             [-1, 64, 7, 7]               0\n",
      "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
      "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
      "             ReLU-21            [-1, 128, 4, 4]               0\n",
      "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
      "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
      "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
      "             ReLU-26            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
      "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
      "             ReLU-30            [-1, 128, 4, 4]               0\n",
      "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
      "             ReLU-33            [-1, 128, 4, 4]               0\n",
      "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
      "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
      "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
      "             ReLU-37            [-1, 256, 2, 2]               0\n",
      "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
      "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
      "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
      "             ReLU-42            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
      "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
      "             ReLU-46            [-1, 256, 2, 2]               0\n",
      "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
      "             ReLU-49            [-1, 256, 2, 2]               0\n",
      "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
      "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-53            [-1, 512, 1, 1]               0\n",
      "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
      "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-58            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
      "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-62            [-1, 512, 1, 1]               0\n",
      "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
      "             ReLU-65            [-1, 512, 1, 1]               0\n",
      "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                    [-1, 7]           3,591\n",
      "================================================================\n",
      "Total params: 11,180,103\n",
      "Trainable params: 11,180,103\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.09\n",
      "Params size (MB): 42.65\n",
      "Estimated Total Size (MB): 43.75\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#model = resnet18(num_classes=n_classes)\n",
    "#summary(model, (3, 28, 28)) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
