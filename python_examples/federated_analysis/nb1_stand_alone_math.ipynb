{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e583e7-6d3f-4fca-9523-d5f816365ca1",
   "metadata": {},
   "source": [
    "### Use case example: Federated Analysis\n",
    "\n",
    "As a clinical researcher, Alice wants to know if a specific treatment for a certain disease is effective.\n",
    "\n",
    "Background: Alice has 12 patients with the diagnosis, of which 7 have received a specific treatment. We assume that the effect of the treatment is indicated by the lab value X. The mean values of X for both cohorts indicate that the treatment has an effect, but there is no statistical significance due to the small number of patients. \n",
    "\n",
    "Alice’s has searched for other sources of data and discovered that it is spread out over a network of edge nodes that support federated analysis through secure multiparty computation. Spread across all nodes there are a total of 1298 patients with the same diagnosis, of which 357 have received the specific treatment. By using more data, she can increase the statistical significance as the number of patients increases. The problem is that to protect the privacy of the people in the distributed database, Alice cannot simply download the data sets to her own computer and perform the analysis. Instead she must perform the calculations remotely at each edge node and then aggregate under homomoprhic encrytion, which is a cryptosystem that supports calculation on encrypted variables.\n",
    "\n",
    "Challenge: The data that Alice needs is spread across multiple sources and there is no possibility of central collection due to privacy protection legislation. Even partial results from the analysis must be hidden from all parties, including Alice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6f70f-7f18-4388-b215-2e5f8ca9802b",
   "metadata": {},
   "source": [
    "### Notation\n",
    "\n",
    "Let's assume that there are $K$ edge nodes in the federated network. For the cohorts available at node $k$, we assume that $N_{1,k}$ patients have recieved the treatment, and that $N_{0,k}$ are untreated. For each patient $i$ at node $k$ we denote the measured lab value by $X_{i,k}$ and the treatment status by $Y_{i,k}$.\n",
    "\n",
    "Alice wants to know the global average and variance for both cohorts so that she examine the hypothesis that the treatment is effective with statistical significans. That is, she wants to calculate, \n",
    "\n",
    "$$\n",
    "\\mu_0 = \\mathrm{E}(X|Y=0),\\quad \\sigma_0^2 = \\mathrm{Var}(X|Y=0) \n",
    "$$\n",
    "$$\n",
    "\\mu_1 = \\mathrm{E}(X|Y=1),\\quad \\sigma_1^2 = \\mathrm{Var}(X|Y=1) \n",
    "$$\n",
    "\n",
    "that is, the mean and variance for each cohort. She can estimate the above quantities for the patient data ditributed over the edge nodes by using secure multiparty computation based on homomorphic encryption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b2416-d194-4b6f-8dbb-807a50ed1e71",
   "metadata": {},
   "source": [
    "Alice assumes the data is random, independent and normally distributed so she define sample mean and sample variance as\n",
    "$$ \n",
    "\\bar{X}_y = \\mathrm{mean}(X|Y=y) = \\frac{1}{n_y}\\sum_i^{n_y}{x_{i,y}} \n",
    "$$\n",
    "$$ \n",
    "\\bar{S}^2_y = \\mathrm{var}(X|Y=y)  = \\frac{1}{n_y}\\sum_i^{n_y}{( x_{i,y} - \\bar{X}_y)^2 } \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4b837-9b0e-4def-bc44-2cd91391eef4",
   "metadata": {},
   "source": [
    "When calculating the variance each node needs to know the calculated mean.\n",
    "\n",
    "Instead of calulating the mean and it sending back and do multiple roundtrips in the Sardin framework to calculate the variance, Alice expands the variance formula\n",
    " $$\n",
    " \\frac{1}{n}\\sum_i^n{( x_i - \\bar{X})^2 } =\n",
    " $$\n",
    "  $$ = \\frac{1}{n}\\sum_i^n{x_i}^2 - 2\\cdot \\bar{X} \\cdot \\frac{1}{n}\\sum_i^n{x_i} + \\bar{X}^2\\frac{1}{n}\\sum_i^n{1} = \n",
    "  $$\n",
    "$$ = \\frac{1}{n}\\sum_i^n{x_i^2} - \\bar{X}^2 \n",
    "$$\n",
    "For unbiased variance\n",
    "$$ S^2  = \\frac{1}{n-1}\\sum_i^n{x_i^2} - \\frac{n}{n-1}\\bar{X}^2 \n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6a37a-44b9-4416-94c7-0f3ad2549e5f",
   "metadata": {},
   "source": [
    "To calculate the mean and variance we need to aggregate 3 variables, the number of observations (patients), the variable, and the square of the variable \n",
    "$$\\{n_y, \\ x_{i,y}, \\ x_{i,y}^2\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5640b92-6562-4007-abb8-fc8775ea4fe9",
   "metadata": {},
   "source": [
    "### Prerequisites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7318098e-1491-4d4e-851c-ac030b17eed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tenseal\n",
      "  Downloading tenseal-0.3.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/rise/.local/lib/python3.7/site-packages (1.21.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
      "Installing collected packages: tenseal\n",
      "Successfully installed tenseal-0.3.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.7 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tenseal numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ceb716a-eec5-455e-95bf-8e8e80004fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex, display\n",
    "from scipy.stats import t as t_test\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286034f4-afc1-4e2c-be71-d73be15757a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the context to encrypt data\n",
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    "          )\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**40\n",
    "\n",
    "encrypt_flag = True # True / False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0944c866-7273-4c79-bc7a-554c4d75583c",
   "metadata": {},
   "source": [
    "### Create sudo data for toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f513dd-7bde-4129-9a35-3605bbb192bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getData\n",
    "\n",
    "# Get data from patients without or without treatment\n",
    "treatment = 0 # 0/1\n",
    "\n",
    "# Number of edge nodes to participate\n",
    "nodes = 7\n",
    "\n",
    "# To manage the simulate data retrieval for each independent node, we keep all data in one vector \n",
    "node_data = []\n",
    "for i in range(nodes):\n",
    "    node_data.append(getData(treatment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c6d49-8564-4803-bc32-aba8398c7146",
   "metadata": {},
   "source": [
    "### Define functions to be run on edge nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c66b085d-665d-44f4-b4ff-8b09eee13eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return number of observation\n",
    "def get_n(x):\n",
    "    return len(x)\n",
    "\n",
    "# Return sum of all observations\n",
    "def get_xi(x):\n",
    "    return x.sum()\n",
    "\n",
    "# Return sum of squared observations\n",
    "def get_xi_2(x):\n",
    "    return x.dot(x)\n",
    "\n",
    "# The function that will be doing the calculations on \"each node\"\n",
    "def local_calculation(x):\n",
    "\n",
    "    # The variables Alice are interested by in this example is the mean and variance\n",
    "    # In the math section above we showed that in order for Alice to calculate mean and variance, this function\n",
    "    #     will calculate the variables needed\n",
    "\n",
    "    # INPUT: \n",
    "    #    x: observation data points from the local registry\n",
    "    # OUTPUT:\n",
    "    #    obs: number of observations\n",
    "    #    xi: sum of observations\n",
    "    #    xi_2: sum of squared observations\n",
    "\n",
    "    n = get_n(x)\n",
    "    xi = get_xi(x)\n",
    "    xi_2 = get_xi_2(x)\n",
    "    \n",
    "    return n, xi, xi_2\n",
    "    \n",
    "# Simulating the distributed edge node calculations\n",
    "encrypted_node_data = []\n",
    "for data in node_data:\n",
    "    \n",
    "    # Run Alices functions on each edge node\n",
    "    n, xi, xi_2 = local_calculation(data)\n",
    "\n",
    "    if encrypt_flag:\n",
    "        # Encrypt data the same each node\n",
    "        calculated_data = ts.ckks_vector(context, [n, xi, xi_2])\n",
    "    else:\n",
    "        calculated_data = np.array([n, xi, xi_2])\n",
    "\n",
    "    # Gather all encrypted data\n",
    "    encrypted_node_data.append(calculated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a40e969-91aa-4de6-a4d8-2f68c15600a4",
   "metadata": {},
   "source": [
    "#####\n",
    "<!-- låt säga vi har x data punkter att addera\n",
    "$$\n",
    "\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}+... = \\sum^n_{k=1} (\\frac{1}{2})^k = 1, n\\rightarrow\\inf\n",
    "$$\n",
    "n godtyckligt (5)\n",
    "$$\n",
    "\\sum^5_{k=1} = \\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}+\\frac{1}{16}+\\frac{1}{32}\n",
    "$$\n",
    "multiplicera med 32 (2^n)\n",
    "$$\n",
    "32\\sum^5_{k=1} = 32*(\\frac{1}{2}+\\frac{1}{4}+\\frac{1}{8}+\\frac{1}{16}+\\frac{1}{32}) = 16+8+4+2+1 = 31\n",
    "$$ -->\n",
    "<!-- \n",
    "Mängden additioner genom ett binary-tree med ett godtyckligt antal termer $2^n \\,,\\, n \\in \\mathbb{N}$ kan enkelt visas vara \n",
    "$$\n",
    "2^n\\sum^n_{k=1}(\\frac{1}{2})^k = 2^n-1 \\quad, \\quad n<\\infty\n",
    "$$\n",
    "vilket också är samma mängd additioner som för en naiv summation av samma antal.\n",
    "Däremot skiljer det sig in hur CKKS adderar noise. Alice inser att i en naiv summering av en vector med CKKS ciphertexts\n",
    "$$\n",
    "\\sum_i^N C_i = C_1 + C_2 + ...\n",
    "$$\n",
    "kommer öka noise linjärt. För att visa varför, skriver hon om föregående summa\n",
    "$$\n",
    "\\sum_i^N C_i = \\sum_i^{k-1} C_i + \\sum_k^N C_k = C^{sum}_{k-1} + \\sum_k^N C_k\n",
    "$$\n",
    "där $ C^{sum}_k $ är en partiell summa. Noise nivån i den partiella summan kan beskrivas som\n",
    "$$\n",
    "noise(C^{sum}_{k-1}) = {max_{noise}(C^{sum}_{k-2} \\,,\\, C_{k-1})} + \\sigma\n",
    "$$\n",
    "där $\\sigma$ är en godtycklig mängd noise\n",
    "Alice tänker ett enklare fall där $\\sigma$ är konstant och identiskt för alla additioner och hon kommer fram till att i detta fall kommer den slutliga noise nivån vara \n",
    "$$\n",
    "noise(\\sum_i^N C_i) = \\sum_i^N ({max_{noise}(C^{sum}_{i-1} \\,,\\, C_i)} + \\sigma ) = \\sigma \\cdot N\n",
    "$$\n",
    "Vid addition genom ett binary tree, för godtyckligt antal termar $x_0 \\in \\mathbb{N}^+$ och $Y := \\{2^n | n \\in \\mathbb{N} \\,,\\, 2^n \\leq x_0\\}$ kan man dela upp additionerna till flera binary-trees där\n",
    "$$\n",
    "x_1 = \\max(Y) \n",
    "$$\n",
    "$$\n",
    "x_2 = x_0-x_1\n",
    "$$\n",
    "är antalet termer att summeras i ett nästa binary-tree. Detta görs recursivt till man har kompletta binary-tree's.\n",
    "Hur noise nivån ökar kan man se på nedansstående bild.\n",
    "<img src=\"binary_tree.png\" align=\"center\"/>\n",
    "Som Alice ser i bilden så är det antalet \"lager\" i trädet som avgör noise nivån för binary tree summation.\n",
    "för ett tal $2^n \\,,\\, n \\in \\mathbb{N}$ så är antalet lager \n",
    "$$\n",
    "log_2(2^n) = n\n",
    "$$\n",
    "Alice konstaterar att för ett generelt antal termer så är noise growth vid slutförd summation\n",
    "$$\n",
    "\\lceil \\, log_2(x) \\, \\rceil  \\cdot \\sigma\n",
    "$$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24809b9a-31e7-4187-9246-d1a3fefa62b8",
   "metadata": {},
   "source": [
    " The number of additions through a binary tree with an arbitrary number of terms $2^n \\,,\\, n \\in \\mathbb{N}$ can be easily shown to be\n",
    "$$\n",
    "2^n\\sum^n_{k=1} \\left(\\frac{1}{2}\\right)^k = 2^n - 1 \\quad, \\quad n<\\infty\n",
    "$$\n",
    "which is the same number of additions as for a naive summation of the same quantity.\n",
    "\n",
    "However, the difference lies in how CKKS manages the ciphertext modulus. Alice realizes that in a naive summation of a vector with CKKS ciphertexts\n",
    "$$\n",
    "\\sum_i^N C_i = C_1 + C_2 + \\ldots\n",
    "$$\n",
    "the circuit depth increases linearly, and consumes the computational budget. To demonstrate why, she rewrites the previous sum as\n",
    "$$\n",
    "\\sum_i^N C_i = \\sum_i^{k-1} C_i + \\sum_k^N C_k = C^{sum}_{k-1} + \\sum_k^N C_k\n",
    "$$\n",
    "where $C^{sum}_k$ is a partial sum. The modulus level in the partial sum can be described as\n",
    "$$\n",
    "\\text{modulus}(C^{sum}_{k-1}) = \\max_{\\text{modulus}}(C^{sum}_{k-2} \\,,\\, C_{k-1}) + \\Delta\n",
    "$$\n",
    "where $\\Delta$ is the scaling factor.\n",
    "\n",
    "Alice considers a simpler case where $\\Delta$ is identical for all ciphertexts, and she concludes that in this scenario, the final modulus level will be\n",
    "$$\n",
    "\\text{modulus}(\\sum_i^N C_i) = \\sum_i^N (\\max_{\\text{modulus}}(C^{sum}_{i-1} \\,,\\, C_i) + \\Delta ) = \\Delta \\cdot N\n",
    "$$\n",
    "\n",
    "When adding through a binary tree, for an arbitrary number of terms $x_0 \\in \\mathbb{N}^+$ and $Y := \\{2^n | n \\in \\mathbb{N} \\,,\\, 2^n \\leq x_0\\}$, the additions can be divided into several binary trees, where\n",
    "$$\n",
    "x_1 = \\max(Y) \n",
    "$$\n",
    "represents the number of terms in the first binary tree and\n",
    "$$\n",
    "x_2 = x_0 - x_1\n",
    "$$\n",
    "\n",
    "represent the number of terms to be summed in the next binary tree. This process is repeated recursively until complete binary trees are formed.\n",
    "\n",
    "<img src=\"bilder/modulus.png\" align=\"center\"/>\n",
    "\n",
    "The increase in modulus level can be observed in the provided image. Alice realises, the number of \"layers\" in the tree determines the circuit depth, or the modulus level for binary tree summation. For a number $2^n \\,,\\, n \\in \\mathbb{N}$, the number of layers is\n",
    "$$\n",
    "\\log_2(2^n) = n\n",
    "$$\n",
    "\n",
    "Alice also notes that for a general number of terms, the modulus level growth after completing the summation is\n",
    "$$\n",
    "\\lceil \\, \\log_2(x) \\, \\rceil \\cdot \\Delta\n",
    "$$\n",
    "\n",
    "This logic is also follows for multiplication in CKKS. In fact, for multiplication the modulus level growth faster and require much shorter circut depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72431c1-fa82-40cb-bf83-08b1a56d8eb0",
   "metadata": {},
   "source": [
    "### Define the accumulator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fdc581-86af-4e80-b7ed-8a0f2813a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary-tree summation\n",
    "def binary_tree_accumulator(node_data):\n",
    "    # [ .. [[c1 + c2] + [c3 + c4]] .. ]\n",
    "    if not node_data:\n",
    "        return 0\n",
    "    elif len(node_data) == 1:\n",
    "        return node_data[0]\n",
    "    else:\n",
    "        mid = len(node_data) // 2\n",
    "        left_sum = binary_tree_accumulator(node_data[:mid])\n",
    "        right_sum = binary_tree_accumulator(node_data[mid:])\n",
    "        return left_sum + right_sum\n",
    "\n",
    "\n",
    "# Naiv summation\n",
    "def naiv_accumulator(node_data):\n",
    "    accumulated_data = 0\n",
    "    \n",
    "    # [n_1, xi_1, xi^2_1]\n",
    "    # + [n_2, xi_2, xi^2_2]\n",
    "    # + ...\n",
    "    # = [n, xi, xi^2]\n",
    "    \n",
    "    for data in node_data:\n",
    "        accumulated_data += data\n",
    "    return accumulated_data\n",
    "    \n",
    "encrypted_accumulated_data = binary_tree_accumulator(encrypted_node_data)\n",
    "# encrypted_accumulated_data = naiv_accumulator(encrypted_node_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc0bba-c8a1-404e-bc71-ed9cbb23d3b7",
   "metadata": {},
   "source": [
    "### Define the decode function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed8dfb8-0f70-4ca0-8b1c-322a7e650f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The decode function will decrypt and reveal the accumulated data to Alice, only after all the previous steps have been completed succesfully\n",
    "def decode(x):\n",
    "    if encrypt_flag:\n",
    "        return x.decrypt()\n",
    "    return x\n",
    "\n",
    "accumulated_data = decode(encrypted_accumulated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf86a6-2210-41af-a1eb-377f6826a746",
   "metadata": {},
   "source": [
    "### Define Alices function that will use the accumulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1f53c5f-19ac-4561-a940-4cec6bcaf5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number observations = 938, mean = 85.34, var = 3908.13, std = 62.52\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_and_var(variables, unbiased): # vec = [n, x, x^2]\n",
    "    \n",
    "    n = round(variables[0])\n",
    "    x = variables[1]\n",
    "    x_2 = variables[2]\n",
    "\n",
    "    mean = x/n\n",
    "    \n",
    "    # Calculate biased or unbiased variance based on the expanded formula\n",
    "    if unbiased:\n",
    "        var = x_2/(n-1) - (n/(n-1))*(mean**2)\n",
    "    else:\n",
    "        var = x_2/n - mean**2\n",
    "\n",
    "    return n, mean, var\n",
    "\n",
    "unbiased = True\n",
    "n_0, mean_treatment_0, var_treatment_0 = calculate_mean_and_var(accumulated_data, unbiased=unbiased)\n",
    "print(f\"number observations = {n_0}, mean = {mean_treatment_0:.2f}, var = {var_treatment_0:.2f}, std = {var_treatment_0**(1/2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47e41f-a6c8-45b4-a697-a588040f4104",
   "metadata": {},
   "source": [
    "### Perform the same simulation for treated patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc57983-a3c0-48f6-9872-c1258ae7e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number observations = 357, mean = 75.30, var = 1743.65, std = 41.76\n"
     ]
    }
   ],
   "source": [
    "treatment = 1 # 0/1\n",
    "\n",
    "node_data = []\n",
    "encrypted_node_data = []\n",
    "for _ in range(nodes):\n",
    "    \n",
    "    # ---- Inside each node ---- #\n",
    "    data = getData(treatment)\n",
    "    n, xi, xi_2 = local_calculation(data)\n",
    "    \n",
    "    if encrypt_flag:\n",
    "        data = ts.ckks_vector(context, [n, xi, xi_2])\n",
    "    else:\n",
    "        data = np.array([n, xi, xi_2])\n",
    "    # ---- Inside each node ---- #\n",
    "\n",
    "    # ---- Data gets sent to central Sardin server to be accumulated ---- #\n",
    "    node_data.append(data)\n",
    "accumulated_data = binary_tree_accumulator(node_data)\n",
    "\n",
    "# ---- Decode data to Alice ---- # \n",
    "accumulated_data = decode(accumulated_data)\n",
    "\n",
    "unbiased = True\n",
    "n_1, mean_treatment_1, var_treatment_1 = calculate_mean_and_var(accumulated_data, unbiased=unbiased)\n",
    "print(f\"number observations = {n_1}, mean = {mean_treatment_1:.2f}, var = {var_treatment_1:.2f}, std = {var_treatment_1**(1/2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b20a7-a1d9-4212-9050-ef88ed32e97f",
   "metadata": {},
   "source": [
    "######\n",
    "## Perform analysis with the retrieved data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5228a5e-a294-48fb-b216-1b40edd6ac89",
   "metadata": {},
   "source": [
    "Alice wants to investigate whether the two cohorts are significantly different or not and sets the null hypothesis as the two cohorts having the same mean\n",
    "$$\n",
    "H_0 : \\mu_0 = \\mu_1\n",
    "$$\n",
    "\n",
    "and the alternative hypoothesis as the two cohorts mean differs\n",
    "$$\n",
    "H_1 : \\mu_0 \\ne \\mu_1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be9ed2-3019-4171-afa6-d1fb27282a70",
   "metadata": {},
   "source": [
    "Alice makes the assumptions that the data is random, independent and normally distributed but she also knows that the effect of the medication is not entierly clear so she can't make the assumtion of equal variance for the two cohorts\n",
    "\n",
    "She then uses the Welche's t-test statistic\n",
    "$$\n",
    "t = \\frac{\\bar{X_0}-\\bar{X_1}}{\\sqrt{\\frac{S^2_0}{n_0} + \\frac{S^2_1}{n_1}}}\n",
    "$$\n",
    "where $S^2_0$ and $S^2_1$ is the unbiased sample variance, $ \\bar{X_0} $, $\\bar{X_1}$ is the sample mean and $n_0$, $n_1$ the number of data points\n",
    "\n",
    "and the degrees of freedom is calculated as\n",
    "$$\n",
    " d.f. = \\frac{(\\frac{S^2_0}{n_0} + \\frac{S^2_1}{n_1})^2}{\\frac{(S^2_0/n_0)^2}{n_0-1} + \\frac{(S^2_1/n_1)^2}{n_1-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65644398-7d23-4040-9559-012e3c87c8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Alice calculates the t statistic\\begin{equation*}\n",
       "t = \\frac{ 85.34 - 75.30 }\n",
       "{ \\sqrt{ \\frac{ 3908.13 }{ 938 } + \\frac{ 1743.65 }{ 357 } } } = 3.34\n",
       "\\end{equation*}\n",
       "and the degrees of freedom\\begin{equation*}\n",
       "d.f. = \\frac{ ( \\frac{3908.13}{938} + \\frac{1743.65}{357})^2 } \n",
       "{ \\frac{(3908.13/938)^2}{937} + \\frac{(1743.65/357)^2}{356}}\n",
       "= 957.66\n",
       "\\end{equation*}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (mean_treatment_0 - mean_treatment_1) / (math.sqrt(var_treatment_0 / n_0 + var_treatment_1 / n_1))\n",
    "df = ( var_treatment_0 / n_0 + var_treatment_1 / n_1 )**2 / ( ((var_treatment_0 / n_0)**2) / (n_0-1) + ((var_treatment_1 / n_1)**2) / (n_1-1) )\n",
    "\n",
    "Latex(\n",
    "\"Alice calculates the t statistic\" \n",
    "+ f\"\"\"\\\\begin{{equation*}}\n",
    "t = \\\\frac{{ { \"%.2f\" % mean_treatment_0 } - { \"%.2f\" % mean_treatment_1} }}\n",
    "{{ \\\\sqrt{{ \\\\frac{{ { \"%.2f\" % var_treatment_0} }}{{ {n_0} }} + \\\\frac{{ { \"%.2f\" % var_treatment_1} }}{{ { n_1 } }} }} }} = { \"%.2f\" % t }\n",
    "\\\\end{{equation*}}\n",
    "\"\"\"\n",
    "+ \"and the degrees of freedom\" \n",
    "+  f\"\"\"\\\\begin{{equation*}}\n",
    "d.f. = \\\\frac{{ ( \\\\frac{{{\"%.2f\" % var_treatment_0}}}{{{n_0}}} + \\\\frac{{{\"%.2f\" %var_treatment_1}}}{{{n_1}}})^2 }} \n",
    "{{ \\\\frac{{({\"%.2f\" % var_treatment_0}/{n_0})^2}}{{{n_0-1}}} + \\\\frac{{({\"%.2f\" % var_treatment_1}/{n_1})^2}}{{{n_1-1}}}}}\n",
    "= { \"%.2f\" % df }\n",
    "\\\\end{{equation*}}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58f2cb75-7858-4d66-8a3e-473b27fac21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Alice wants to use a 95.0% confidence level for the test so she looks up the t-score in a table, $t_{score} = 1.9624 $ "
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       " Since t > $t_{score}$ Alice can reject the null hypothesis"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       " Infact at a confidence level of 99.91% she can reject the null hypothesis "
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 0.05\n",
    "\n",
    "# For a two-tail test we use half of p to get the correct tabular value for the t statistic\n",
    "t_score = t_test.isf(p/2, df)\n",
    "\n",
    "# Can Alice reject the null hypothesis?\n",
    "reject = True if t > t_score else False\n",
    "\n",
    "# At what confidence level can Alice reject the null hypothesis\n",
    "confidence_level = 1-t_test.sf(t, df)*2\n",
    "\n",
    "display(Latex(\n",
    "f\"\"\"Alice wants to use a {(1-p)*100}% confidence level for the test so she looks up the t-score in a table, $t_{{score}} = {\"%.4f\" % t_score } $ \"\"\"\n",
    "))\n",
    "display(Latex(\n",
    "f\"\"\" Since t {\">\" if reject else \"≤\"} $t_{{score}}$ Alice {\"can\" if reject else \"can't\"} reject the null hypothesis\"\"\"\n",
    "))\n",
    "display(Latex(\n",
    "f\"\"\" Infact at a confidence level of {\"%.2f\" % (confidence_level*100)}% she can reject the null hypothesis \"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0ad46-edd7-49d8-9c15-49904a522228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
